{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30b73322-2f90-47de-af21-8ce2c1575907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-17 19:58:12--  https://huggingface.co/datasets/CopyleftCultivars/SemiSynthetic_Composting_Knowledge_For_Agriculture/resolve/main/SemiSynthetic_Composting_Knowledge_For_Agriculture.json?download=true\n",
      "Resolving huggingface.co (huggingface.co)... 3.163.189.74, 3.163.189.90, 3.163.189.114, ...\n",
      "Connecting to huggingface.co (huggingface.co)|3.163.189.74|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 31505 (31K) [text/plain]\n",
      "Saving to: ‘SemiSynthetic_Composting_Knowledge_For_Agriculture.json?download=true’\n",
      "\n",
      "SemiSynthetic_Compo 100%[===================>]  30.77K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-02-17 19:58:13 (680 MB/s) - ‘SemiSynthetic_Composting_Knowledge_For_Agriculture.json?download=true’ saved [31505/31505]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://huggingface.co/datasets/CopyleftCultivars/SemiSynthetic_Composting_Knowledge_For_Agriculture/resolve/main/SemiSynthetic_Composting_Knowledge_For_Agriculture.json?download=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9654257-da99-4742-ba5e-55ee756055a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import intel_extension_for_pytorch as ipex\n",
    "import requests\n",
    "from tokenizers import normalizers\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import transformers\n",
    "import torch\n",
    "import os\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fc3bfa5-a908-4ea1-b8b1-98a9b511f6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"xpu\" if torch.xpu.is_available() else \"cpu\"\n",
    "\n",
    "def serialize_recipes(data):\n",
    "    serial = []\n",
    "    for recipe in data:\n",
    "        recipe_string = \"\"\n",
    "        for key, value in recipe.items():\n",
    "            recipe_string += ''.join(key) + \":\\n\" + \"\".join(value) + \"\\n\"\n",
    "        serial.append(recipe_string)\n",
    "    return serial\n",
    "\n",
    "database = json.load(open(\"./SemiSynthetic_Composting_Knowledge_For_Agriculture.json?download=true\", \"rb\"))\n",
    "database = serialize_recipes(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5fb79e3d-1f0c-417f-aa1d-2355a2a14a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5f5e5b942c4503a78ac599eaccaadf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78dec99160e1405b90420d5af4141067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generating document embeddings:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VECTOR_DB = \"./vector_db.pt\"\n",
    "model_name = 'Intel/neural-chat-7b-v3-3'\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "embedder = transformers.pipeline('feature-extraction', model=model, tokenizer=tokenizer)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def embed_data(data):\n",
    "    embedded = []\n",
    "    for i in tqdm(data, desc=\"generating document embeddings: \"):\n",
    "        embedded.append(i)\n",
    "    return embedded\n",
    "\n",
    "embedded_database = embed_data(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "225e0c2b-9555-4025-bb21-b5588893e258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_response(query, corpus):\n",
    "    similarities = []\n",
    "    for doc in corpus:\n",
    "        q_features = embedder(query)[0]\n",
    "        d_features = embedder(doc)[0]\n",
    "        min_size = min(len(q_features), len(d_features))\n",
    "        q_features = torch.tensor(q_features[0:-1:len(q_features) - 1//min_size])\n",
    "        d_features = torch.tensor(d_features[0:-1:len(d_features) - 1//min_size])\n",
    "        similarity = torch.sum(torch.nn.functional.cosine_similarity(d_features.float(), \n",
    "                                                           q_features.float())).item()\n",
    "        similarities.append(similarity)\n",
    "    return database[similarities.index(max(similarities))]\n",
    "\n",
    "def generate_response(system_input, user_input):\n",
    "\n",
    "    # Format the input using the provided template\n",
    "    prompt = f\"### System:\\n{system_input}\\n### User:\\n{user_input}\\n### Assistant:\\n\"\n",
    "\n",
    "    # Tokenize and encode the prompt\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
    "\n",
    "    # Generate a response\n",
    "    outputs = model.generate(inputs, pad_token_id=tokenizer.pad_token_id, max_length=1000, num_return_sequences=1)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract only the assistant's response\n",
    "    return response.split(\"### Assistant:\\n\")[-1]\n",
    "\n",
    "def generate_RAG(user_input):\n",
    "    relevant_document = return_response(user_input, embedded_database)\n",
    "    system_input = f\"\"\"You are a farming assitant named spot that makes recommendations for good farming practices. \n",
    "                You answer in very short sentences and try to be as helpful, and truthful, as possible.\n",
    "                This is a relevant document: {relevant_document}\n",
    "                Compile a reccomendations to the user based primarily on the user input and use the \n",
    "                document to supplment your knowledge of the real world.\"\"\"\n",
    "    return generate_response(system_input, user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4be272c4-ea9b-4285-a422-5089b1e33592",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Im not sure how to plant my potatoes, can you help me out?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5f59d8a1-27f3-45fa-a6cb-ce7637d5b94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Plant potatoes in well-prepared soil with good drainage. Choose a sunny location and dig trenches about 6-8 inches deep. Place potato pieces (each with 2-3 eyes) about 12 inches apart in the trench. Cover with soil, leaving about 2 inches of the potato exposed. As the plants grow, continue to mound soil around them to support the stems and prevent sunlight from reaching the potatoes. Water regularly and enjoy your harvest.'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generated using rag with a db of farming knowledge on Intel/neural-chat-7b-v3-3\n",
    "system_input = \"\"\"You are a farming assitant named spot that makes recommendations for good farming practices. \n",
    "                You answer in very short sentences and try to be as helpful, and truthful, as possible.\n",
    "                This is a relevant document: {relevant_document}\n",
    "                Compile a reccomendations to the user based primarily on the user input and use the \n",
    "                document to supplment your knowledge of the real world.\"\"\"\n",
    "generate_RAG(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bc0294b8-0216-4366-8f10-f7208f82171e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Choose well-drained soil, plant seeds 4-6 inches apart, and ensure proper watering and sunlight.'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generated using Intel/neural-chat-7b-v3-3\n",
    "system_input = f\"\"\"You are a farming assitant named spot that makes recommendations for good farming practices. \n",
    "                You answer in very short sentences and try to be as helpful, and truthful, as possible.\n",
    "                Compile a reccomendations to the user based on the user input.\"\"\"\n",
    "generate_response(system_input, user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ab499d-9016-49dd-b4d5-0bc73e921637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
