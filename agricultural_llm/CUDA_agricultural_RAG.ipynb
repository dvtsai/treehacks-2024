{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30b73322-2f90-47de-af21-8ce2c1575907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-18 06:24:04--  https://huggingface.co/datasets/CopyleftCultivars/SemiSynthetic_Composting_Knowledge_For_Agriculture/resolve/main/SemiSynthetic_Composting_Knowledge_For_Agriculture.json?download=true\n",
      "Resolving huggingface.co (huggingface.co)... 2600:9000:234c:f600:17:b174:6d00:93a1, 2600:9000:234c:9800:17:b174:6d00:93a1, 2600:9000:234c:a200:17:b174:6d00:93a1, ...\n",
      "Connecting to huggingface.co (huggingface.co)|2600:9000:234c:f600:17:b174:6d00:93a1|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 31505 (31K) [text/plain]\n",
      "Saving to: ‘SemiSynthetic_Composting_Knowledge_For_Agriculture.json?download=true’\n",
      "\n",
      "SemiSynthetic_Compo 100%[===================>]  30.77K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2024-02-18 06:24:04 (41.2 MB/s) - ‘SemiSynthetic_Composting_Knowledge_For_Agriculture.json?download=true’ saved [31505/31505]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !wget https://huggingface.co/datasets/CopyleftCultivars/SemiSynthetic_Composting_Knowledge_For_Agriculture/resolve/main/SemiSynthetic_Composting_Knowledge_For_Agriculture.json?download=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9654257-da99-4742-ba5e-55ee756055a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# import intel_extension_for_pytorch as ipex\n",
    "import requests\n",
    "from tokenizers import normalizers\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import transformers\n",
    "import torch\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import speech_recognition as sr\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fc3bfa5-a908-4ea1-b8b1-98a9b511f6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)\n",
    "\n",
    "def serialize_recipes(data):\n",
    "    serial = []\n",
    "    for recipe in data:\n",
    "        recipe_string = \"\"\n",
    "        for key, value in recipe.items():\n",
    "            recipe_string += ''.join(key) + \":\\n\" + \"\".join(value) + \"\\n\"\n",
    "        serial.append(recipe_string)\n",
    "    return serial\n",
    "\n",
    "database = json.load(open(\"./SemiSynthetic_Composting_Knowledge_For_Agriculture.json download=true\", \"rb\"))\n",
    "database = serialize_recipes(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fb79e3d-1f0c-417f-aa1d-2355a2a14a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2bd7a112f742fa880b554680a2e860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generating document embeddings:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VECTOR_DB = \"./vector_db.pt\"\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "embedder = transformers.pipeline('feature-extraction', model=model, tokenizer=tokenizer)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def embed_data(data):\n",
    "    embedded = []\n",
    "    for i in tqdm(data, desc=\"generating document embeddings: \"):\n",
    "        embedded.append(i)\n",
    "    return embedded\n",
    "\n",
    "embedded_database = embed_data(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "225e0c2b-9555-4025-bb21-b5588893e258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_response(query, corpus):\n",
    "    similarities = []\n",
    "    for doc in corpus:\n",
    "        q_features = embedder(query)[0]\n",
    "        d_features = embedder(doc)[0]\n",
    "        min_size = min(len(q_features), len(d_features))\n",
    "        q_features = torch.tensor(q_features[0:-1:len(q_features) - 1//min_size])\n",
    "        d_features = torch.tensor(d_features[0:-1:len(d_features) - 1//min_size])\n",
    "        similarity = torch.sum(torch.nn.functional.cosine_similarity(d_features.float(), \n",
    "                                                           q_features.float())).item()\n",
    "        similarities.append(similarity)\n",
    "    return database[similarities.index(max(similarities))]\n",
    "\n",
    "def generate_response(system_input, user_input):\n",
    "\n",
    "    # Format the input using the provided template\n",
    "    prompt = f\"### System:\\n{system_input}\\n### User:\\n{user_input}\\n### Assistant:\\n\"\n",
    "\n",
    "    # Tokenize and encode the prompt\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
    "\n",
    "    # Generate a response\n",
    "    outputs = model.generate(inputs, pad_token_id=tokenizer.pad_token_id, max_length=300, num_return_sequences=1)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract only the assistant's response\n",
    "    return response.split(\"### Assistant:\\n\")[-1]\n",
    "\n",
    "def generate_RAG(user_input):\n",
    "    relevant_document = return_response(user_input, embedded_database)\n",
    "    system_input = f\"\"\"You are a farming assitant named spot that makes recommendations for good farming practices. \n",
    "                You answer in very short sentences and are very helpful and truthful.\n",
    "                Formulate your answer using this document: {relevant_document}\"\"\"\n",
    "    return generate_response(system_input, user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93b4a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpeakText(command):\n",
    "    # Initialize the engine\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(command) \n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4be272c4-ea9b-4285-a422-5089b1e33592",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Im not sure how to plant my potatoes, can you help me out?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f59d8a1-27f3-45fa-a6cb-ce7637d5b94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a step-by-step guide on how to plant potatoes:\n",
      "\n",
      "1. Choose a potato variety that is suitable for your climate and soil type.\n",
      "2. Dig a hole that is twice the depth of the potato plant.\n",
      "3. Fill the hole with potting soil.\n",
      "4. Place the potato plant in the hole, making sure it is level with the soil.\n",
      "5. Fill the hole with more potting soil, making sure it is evenly distributed.\n",
      "6. Water the plant thoroughly.\n",
      "7. Place a st\n"
     ]
    }
   ],
   "source": [
    "# generated using rag with a db of farming knowledge on Intel/neural-chat-7b-v3-3\n",
    "system_input = \"\"\"You are a farming assitant named spot that makes recommendations for good farming practices. \n",
    "                You answer in very short sentences and are very helpful and truthful.\n",
    "                Formulate your answer using this document: {relevant_document}\"\"\"\n",
    "advice = generate_RAG(user_prompt)\n",
    "print(advice)\n",
    "SpeakText(advice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc0294b8-0216-4366-8f10-f7208f82171e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I'd be happy to help you out. Here are some tips for planting potatoes:\n",
      "1. Choose a good location: Potatoes prefer well-drained soil with a pH between 6.0 and 7.0. Choose a spot that receives at least 6 hours of direct sunlight per day.\n",
      "2. Dig a hole: Use a shovel or garden fork to dig a hole that is twice the depth of the potato you want to plant. Make sure the hole is slightly larger than the potato.\n",
      "3. Fill the hole: Fill the hole with a mixture of potting soil and compost. Make sure the soil is moist but not waterlogged.\n",
      "4. Plant the potato: Place the potato in the hole, making sure it is level with the soil. Firmly press the potato down into the soil.\n",
      "5. Water the potato: Water the potato thoroughly, making sure it is completely submerged in the soil.\n",
      "6. Add fertilizer: If you have fertil\n"
     ]
    }
   ],
   "source": [
    "# generated using Intel/neural-chat-7b-v3-3\n",
    "input = f\"\"\"You are a farming assitant named spot that makes recommendations for good farming practices. \n",
    "                You answer in very short sentences and are very helpful and truthful.\"\"\"\n",
    "print(generate_response(input, user_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa134db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
